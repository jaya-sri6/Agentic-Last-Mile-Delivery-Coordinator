# Project Synapse â€“ Agentic Last-Mile Delivery Coordinator

## Overview
Project Synapse is a multi-agent, LLM-powered AI system designed for autonomous last-mile disruption resolution.
It intelligently coordinates between merchants, drivers, and customers, making human-like decisions and showing transparent reasoning.

## Features
- ğŸ§  **Multi-Agent Orchestration** â€“ Coordinator + Specialist Agents
- ğŸ—‚ **Context Memory** â€“ Past cases inform present decisions
- ğŸ›  **Tool-Driven Reasoning** â€“ Simulated logistics APIs (`check_traffic()`, `get_merchant_status()`, etc.)
- âš¡ **Two-Speed Decision Making** â€“ Immediate reaction + deep optimization
- ğŸ—º **Digital Twin Output** â€“ Real-time map-ready JSON updates
- ğŸš€ **Zero-Shot Tool Adoption** â€“ Learns and uses new tools mid-operation

## Wow Factor 
1. **Feels Human** â€“ Friendly Grab voice, empathy in decision-making
2. **Adapts in Real-Time** â€“ Handles unexpected tools & scenarios
3. **Visually Explains Itself** â€“ Step-by-step reasoning cards
4. **Multi-Agent Teamwork** â€“ Different â€œexpertsâ€ working together

## Setup
```bash
# Clone the repository
git clone <repo-url>
cd project-synapse

# Install dependencies
pip install -r requirements.txt

# Run the application with a scenario
# (Requires OPENAI_API_KEY to be set as an environment variable)
python src/main.py "There is a damaged packaging dispute for order order-789."

# Or run in mock mode (no API key required)
python src/main.py "There is a damaged packaging dispute for order order-789." --mock-llm
```

## Usage

To run the agent, provide a disruption scenario as a command-line argument. The agent can be run in mock mode (which simulates LLM calls and requires no API key) using the `--mock-llm` flag.

### Example Scenarios

#### Overloaded Restaurant
```bash
python src/main.py "My order from merchant-456 is taking a long time." --mock-llm
```

#### Damaged Packaging Dispute
```bash
python src/main.py "There is a dispute over a spilled drink for order-789." --mock-llm
```

#### Recipient Unavailable
```bash
python src/main.py "The recipient for order-abc is unavailable at the delivery address." --mock-llm
```

#### Sudden Traffic Obstruction
```bash
python src/main.py "There is a major traffic obstruction on the route to the airport." --mock-llm
```

## Project Structure
```
.
â”œâ”€â”€ README.md          # This file
â”œâ”€â”€ requirements.txt   # Project dependencies
â”œâ”€â”€ src                # Source code
â”‚   â”œâ”€â”€ main.py        # Main application entry point (CLI)
â”‚   â”œâ”€â”€ agent          # Agent-related code
â”‚   â”‚   â””â”€â”€ coordinator.py # The main Coordinator agent logic
â”‚   â”œâ”€â”€ memory         # Context memory components (placeholder)
â”‚   â”‚   â””â”€â”€ context.py
â”‚   â””â”€â”€ tools          # Simulated API tools
â”‚       â””â”€â”€ logistics.py
â””â”€â”€ tests              # Unit tests
    â”œâ”€â”€ test_agents.py
    â”œâ”€â”€ test_memory.py
    â””â”€â”€ test_tools.py
```

## Agent Design

The core of this project is the `Coordinator` agent, an AI-powered decision-maker built using the **LangChain** framework.

### Architecture
The agent uses a **ReAct (Reasoning and Acting)** architecture. This means it operates in a loop:
1.  **Reason:** Based on the input and its memory, the LLM "thinks" about what to do next. This "chain of thought" is visible in the output.
2.  **Act:** If it decides to gather more information, it selects one of its available **Tools** (e.g., `get_merchant_status`) and specifies the input for it.
3.  **Observe:** The agent executes the tool and receives an **Observation** (the tool's output). This new information is added to its memory.

This loop continues until the agent has enough information to form a final plan, which it then outputs.

### Prompt Engineering
The agent's behavior is guided by a detailed system prompt located in `src/agent/coordinator.py`. This prompt defines:
-   Its **persona** (an intelligent logistics coordinator).
-   Its available **tools** and how to use them.
-   Specific **protocols** for handling different types of scenarios (e.g., disputes, unavailable recipients).

This structured prompting is key to ensuring the agent behaves in a reliable and predictable way.
